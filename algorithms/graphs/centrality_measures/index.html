<!DOCTYPE html>
<html lang="en">

<head>

    
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-66582-32"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-66582-32');
    </script>

    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<meta property="og:title" content="Centrality Measures" />
<meta property="og:description" content="%pylab inline import networkx as nx import pandas as pd Populating the interactive namespace from numpy and matplotlib  layout_dict = dict() def draw_network_plot(graph, color_dict=None): global layout_dict if graph.name not in layout_dict: layout_dict[graph.name] = nx.spring_layout(graph) layout = layout_dict[graph.name] fig, ax = plt.subplots(figsize=(12, 10)) nx.draw_networkx(G, ax=ax, node_color=color_dict, pos=layout) as_series = lambda x: pd.Series(dict(x)).sort_values(ascending=False) The Data Quick. Forget everything you know about Renaissance Italy.
Okay cool. Now, let&rsquo;s take a look at a few of the major families." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://napsterinblue.github.io/notes/algorithms/graphs/centrality_measures/" />



<meta property="article:published_time" content="2021-02-19T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2021-02-19T00:00:00&#43;00:00"/>











<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Centrality Measures"/>
<meta name="twitter:description" content="%pylab inline import networkx as nx import pandas as pd Populating the interactive namespace from numpy and matplotlib  layout_dict = dict() def draw_network_plot(graph, color_dict=None): global layout_dict if graph.name not in layout_dict: layout_dict[graph.name] = nx.spring_layout(graph) layout = layout_dict[graph.name] fig, ax = plt.subplots(figsize=(12, 10)) nx.draw_networkx(G, ax=ax, node_color=color_dict, pos=layout) as_series = lambda x: pd.Series(dict(x)).sort_values(ascending=False) The Data Quick. Forget everything you know about Renaissance Italy.
Okay cool. Now, let&rsquo;s take a look at a few of the major families."/>
<meta name="generator" content="Hugo 0.40.3" />

    
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BlogPosting",
  "headline": "Centrality Measures",
  "url": "https://napsterinblue.github.io/notes/algorithms/graphs/centrality_measures/",
  "wordCount": "2173",
  "datePublished": "2021-02-19T00:00:00&#43;00:00",
  "dateModified": "2021-02-19T00:00:00&#43;00:00",
  "author": {
    "@type": "Person",
    "name": ""
  }
}
</script> 

    <title>Centrality Measures</title>

    
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/css/bootstrap.min.css" integrity="sha384-PsH8R72JQ3SOdhVi3uxftmaW6Vc51MKb0q5P2rRUpPvrszuE4W1povHYgTpBfshb"
        crossorigin="anonymous">

    
    <link href="https://napsterinblue.github.io/notes/css/custom.css" rel="stylesheet">
    <link href="https://napsterinblue.github.io/notes/css/syntax.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Muli:400,500,700" rel="stylesheet">

    <link href="" rel="alternate" type="application/rss+xml" title="Data Science Notes" />

    <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre','code'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>

</head>

<body>

    <nav class="navbar navbar-expand-sm fixed-top">
        <div class="container-fluid">
            <a class="navbar-brand" href="https://napsterinblue.github.io">Movies, Metrics, Musings</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
                aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="nav navbar-nav mr-auto"></ul>
                <ul class="nav navbar-nav">
                    <li><a href="https://napsterinblue.github.io/pages/about.html" title="About">About</a></li>
                    <li><a href="https://napsterinblue.github.io/archives.html" title="Archive">Archive</a></li>
                    <li><a href="https://napsterinblue.github.io/pages/resources.html" title="Resources">Resources</a></li>
                    <li><a href="https://napsterinblue.github.io/notes/" title="Notes">My Notes</a></li>

                </ul>
            </div>
        </div>
    </nav>


    
    <div class="container">
        <div class="row">
            <div class="col-sm-12">

                 


<article>
  <div class="technical_note">
  <header>
    <h1 class="technical_note_title">Centrality Measures</h1>
    <div class="technical_note_date">
      <time datetime=" 2021-02-19T00:00:00Z "> 19 Feb 2021</time>
    </div>
  </header>
  <div class="content">
  

<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="o">%</span><span class="n">pylab</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="kn">as</span> <span class="nn">nx</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span></code></pre></div>
<pre><code>Populating the interactive namespace from numpy and matplotlib
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">layout_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">draw_network_plot</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">color_dict</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">layout_dict</span>
    
    <span class="k">if</span> <span class="n">graph</span><span class="o">.</span><span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">layout_dict</span><span class="p">:</span>
        <span class="n">layout_dict</span><span class="p">[</span><span class="n">graph</span><span class="o">.</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">spring_layout</span><span class="p">(</span><span class="n">graph</span><span class="p">)</span>
        
    <span class="n">layout</span> <span class="o">=</span> <span class="n">layout_dict</span><span class="p">[</span><span class="n">graph</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
    
    <span class="n">nx</span><span class="o">.</span><span class="n">draw_networkx</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">node_color</span><span class="o">=</span><span class="n">color_dict</span><span class="p">,</span> <span class="n">pos</span><span class="o">=</span><span class="n">layout</span><span class="p">)</span>
    
    
<span class="n">as_series</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<h2 id="the-data">The Data</h2>

<p>Quick. Forget <em>everything</em> you know about Renaissance Italy.</p>

<p>Okay cool. Now, let&rsquo;s take a look at a few of the major families.</p>

<p><strong>Note</strong>: For simplicity this data model doesn&rsquo;t burden us with keeping all family <em>members</em> straight. Similarly, all of the edges represent <em>symmetric</em> relationships from family to family (e.g. marriage, pact, etc) and doesn&rsquo;t allow for such realistic, <em>directioned</em> relationships as &ldquo;owes money to,&rdquo; &ldquo;insulted,&rdquo; or anything of that nature.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">florentine_families_graph</span><span class="p">()</span>
<span class="n">G</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;florentine&#39;</span>

<span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_4_0.png" alt="png" /></p>

<p>Looking at this, and considering the famous-ish-ness of the data, we might be inclined to ask: &ldquo;which family is most powerful and why?&rdquo;&ndash; I&rsquo;m sure 15th century Italy did.</p>

<p>In a graph context, we might consider &ldquo;most powerful&rdquo; as &ldquo;most important.&rdquo; So how, then, do we determine a node&rsquo;s importance in a network?</p>

<h2 id="various-centrality-measures">Various Centrality Measures</h2>

<p>There&rsquo;s no one-size-fits-all measure of a node&rsquo;s centrality within a network. As such, I&rsquo;m going to breeze through a few popular metrics and give a brief overview of their trade-offs.</p>

<h3 id="degree-centrality">Degree Centrality</h3>

<p>This is an easy one. And probably the most intuitive. &ldquo;What percent of all other nodes is this node connected to?&rdquo;</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">dc</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">degree_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">dc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">dc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;degree&#39;</span><span class="p">)</span>

<span class="n">dc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.428571
Guadagni        0.285714
Strozzi         0.285714
Bischeri        0.214286
Albizzi         0.214286
Tornabuoni      0.214286
Ridolfi         0.214286
Peruzzi         0.214286
Castellani      0.214286
Salviati        0.142857
Barbadori       0.142857
Lamberteschi    0.071429
Ginori          0.071429
Pazzi           0.071429
Acciaiuoli      0.071429
Name: degree, dtype: float64
</code></pre>

<p>Here, the Medicis are the clear frontrunner, nearly twice the value of the second-most-central family.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">dc</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_8_0.png" alt="png" /></p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">as_series</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">degree</span><span class="p">(</span><span class="n">G</span><span class="p">))</span></code></pre></div>
<pre><code>Medici          6
Guadagni        4
Strozzi         4
Bischeri        3
Albizzi         3
Tornabuoni      3
Ridolfi         3
Peruzzi         3
Castellani      3
Salviati        2
Barbadori       2
Lamberteschi    1
Ginori          1
Pazzi           1
Acciaiuoli      1
dtype: int64
</code></pre>

<h3 id="closeness-centrality">Closeness Centrality</h3>

<p>Closeness centrality measures &ldquo;how close is this node to every other node&rdquo; by taking, for each node,</p>

<pre><code>1 / avg_dist_to_all_nodes
</code></pre>

<p>or</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">(</span>
    <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span>
        <span class="nb">sum</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
               <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">shortest_path_length</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;Medici&#39;</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">other</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span>
                <span class="k">if</span> <span class="n">other</span> <span class="o">!=</span> <span class="s1">&#39;Medici&#39;</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span>
            <span class="p">)</span>
       <span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
   <span class="p">)</span>
<span class="p">)</span></code></pre></div>
<pre><code>0.5599999999999999
</code></pre>

<p>this is wedged between two extremes:</p>

<ul>
<li><code>0</code>: the node is disconnected from everything</li>
<li><code>1</code>: the node is a &lsquo;hub&rsquo; and one step away from all other nodes in the network</li>
</ul>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">cc</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">cc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;closeness&#39;</span><span class="p">)</span>

<span class="n">cc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.560000
Ridolfi         0.500000
Albizzi         0.482759
Tornabuoni      0.482759
Guadagni        0.466667
Barbadori       0.437500
Strozzi         0.437500
Bischeri        0.400000
Salviati        0.388889
Castellani      0.388889
Peruzzi         0.368421
Acciaiuoli      0.368421
Ginori          0.333333
Lamberteschi    0.325581
Pazzi           0.285714
Name: closeness, dtype: float64
</code></pre>

<p>An even-er playing field.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">cc</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_15_0.png" alt="png" /></p>

<p>This shouldn&rsquo;t come as a huge shock, however, as there isn&rsquo;t a TON of variation between max and min distance between any two nodes.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">nx</span><span class="o">.</span><span class="n">radius</span><span class="p">(</span><span class="n">G</span><span class="p">)</span></code></pre></div>
<pre><code>3
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">nx</span><span class="o">.</span><span class="n">diameter</span><span class="p">(</span><span class="n">G</span><span class="p">)</span></code></pre></div>
<pre><code>5
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">nx</span><span class="o">.</span><span class="n">eccentricity</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;Medici&#39;</span><span class="p">)</span></code></pre></div>
<pre><code>3
</code></pre>

<h3 id="harmonic-centrality">Harmonic Centrality</h3>

<p>This is VERY similar to Closeness Centrality. The key difference is where you&rsquo;re doing the averaging.</p>

<p>With Closeness Centrality, we averaged in the denominator. Here, we average the whole fraction, like so:</p>

<pre><code>sum( 1 / (
          (dist(other) for other in nodes)
   ) / (n / 1)
</code></pre>

<p>or</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">sum</span><span class="p">(</span>
    <span class="mi">1</span> <span class="o">/</span>
    <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
                <span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">shortest_path_length</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="s1">&#39;Medici&#39;</span><span class="p">,</span> <span class="n">other</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">other</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span>
                    <span class="k">if</span> <span class="n">other</span> <span class="o">!=</span> <span class="s1">&#39;Medici&#39;</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
   <span class="p">)</span></code></pre></div>
<pre><code>9.5
</code></pre>

<p>Unfortunately, <code>networkx</code> doesn&rsquo;t normalize the values like they do with Closeness Centrality.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">hc</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">harmonic_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">hc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">hc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;harmonic&#39;</span><span class="p">)</span>

<span class="n">hc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          9.500000
Guadagni        8.083333
Ridolfi         8.000000
Albizzi         7.833333
Tornabuoni      7.833333
Strozzi         7.833333
Bischeri        7.200000
Barbadori       7.083333
Castellani      6.916667
Peruzzi         6.783333
Salviati        6.583333
Acciaiuoli      5.916667
Lamberteschi    5.366667
Ginori          5.333333
Pazzi           4.766667
Name: harmonic, dtype: float64
</code></pre>

<p>For the sake of being able to compare Centrality measure to Centrality measure, we&rsquo;ll do that now</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">hc</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">harmonic_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">hc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">hc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;harmoinic&#39;</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hc</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">hc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.678571
Guadagni        0.577381
Ridolfi         0.571429
Albizzi         0.559524
Tornabuoni      0.559524
Strozzi         0.559524
Bischeri        0.514286
Barbadori       0.505952
Castellani      0.494048
Peruzzi         0.484524
Salviati        0.470238
Acciaiuoli      0.422619
Lamberteschi    0.383333
Ginori          0.380952
Pazzi           0.340476
Name: harmoinic, dtype: float64
</code></pre>

<p>At this point, you might find yourself jumping back and forth between this graph an the Closeness Centrality graph. I know I did, and I&rsquo;m the one writing this damn notebook, lol</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">hc</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_27_0.png" alt="png" /></p>

<p>Unfortunately, the book doesn&rsquo;t really expound on the difference between the two, merely offering</p>

<blockquote>
<p>When the closeness of a node is equal to 0 or 1, the harmonic closeness is also near 0 or 1. However, the two centralities in general differ and in the case of [the sample dataset the book had used to this point] are not even strongly correlated</p>
</blockquote>

<p>Bummer.</p>

<p>Thankfully, a bit of poking around and <a href="https://neo4j.com/docs/graph-algorithms/current/labs-algorithms/harmonic-centrality/">these Neo4j docs</a> mention that the Harmonic Centrality was &ldquo;invented to solve the problem the original formula had when dealing with unconnected graphs.&rdquo; And that&rsquo;s good enough for me :)</p>

<h3 id="betweenness">Betweenness</h3>

<p>Betweenness centrality is a really interesting one. It measures &ldquo;the fraction of all possible geodesics that pass thorugh a node&rdquo; and is essentially a measure of &ldquo;how much is this node an essential go-between for any two given nodes?&rdquo;</p>

<p>So we&rsquo;ll start by generating a list of all pairs in a Network</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">itertools</span> <span class="kn">import</span> <span class="n">combinations</span>

<span class="n">all_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
    <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">combinations</span><span class="p">(</span><span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">!=</span> <span class="n">b</span>
<span class="p">)</span>

<span class="c1"># dedupe (&#39;medici&#39;, &#39;albizzi&#39;) vs (&#39;albizzi&#39;, &#39;medici&#39;)</span>
<span class="n">all_pairs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span>
    <span class="nb">tuple</span><span class="p">(</span><span class="nb">sorted</span><span class="p">((</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)))</span> <span class="k">for</span> <span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">all_pairs</span>
<span class="p">))</span></code></pre></div>
<p>Then, we&rsquo;ll remove all mentions of <code>'Medici'</code>&ndash; it doesn&rsquo;t make a ton of sense to consider the Medici family &ldquo;between&rdquo; themselves and another family, yeah?</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">non_medici</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">pair</span>
    <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">all_pairs</span>
    <span class="k">if</span> <span class="s1">&#39;Medici&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pair</span>
<span class="p">]</span>

<span class="nb">len</span><span class="p">(</span><span class="n">non_medici</span><span class="p">)</span></code></pre></div>
<pre><code>91
</code></pre>

<p>This is good. We expect 91 pairs because in a graph of size</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">len</span><span class="p">(</span><span class="n">G</span><span class="p">)</span></code></pre></div>
<pre><code>15
</code></pre>

<p>Subtracting 1 (<code>'Medici'</code>) and applying the &ldquo;number of pairs&rdquo; formula matches</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="p">(</span><span class="mi">14</span> <span class="o">*</span> <span class="mi">13</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span></code></pre></div>
<pre><code>91.0
</code></pre>

<p>And so basically, we want to calculate &ldquo;of all shortest paths between any two nodes, how often is &lsquo;Medici&rsquo; a part of that path?&rdquo;</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="nb">sum</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span>
        <span class="p">(</span><span class="s1">&#39;Medici&#39;</span> <span class="ow">in</span> <span class="n">nx</span><span class="o">.</span><span class="n">shortest_path</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node_a</span><span class="p">,</span> <span class="n">node_b</span><span class="p">)</span>
         <span class="k">for</span> <span class="p">(</span><span class="n">node_a</span><span class="p">,</span> <span class="n">node_b</span><span class="p">)</span> <span class="ow">in</span> <span class="n">non_medici</span><span class="p">),</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span>
    <span class="p">)</span>
<span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">non_medici</span><span class="p">)</span></code></pre></div>
<pre><code>0.5384615384615384
</code></pre>

<p>Finally, it&rsquo;s worth mentioning that this is an <code>O(n^2)</code> operation and thus scales pretty miserably, compared to the <code>O(n)</code>ish measures we&rsquo;ve seen thus far.</p>

<p>Therefore our numbers are <em>a little</em> off, because <code>networkx</code> does some interesting sampling magic behind the scenes to make the computation tractable.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">bc</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">betweenness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">bc</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">bc</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;betweenness&#39;</span><span class="p">)</span>

<span class="n">bc</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.521978
Guadagni        0.254579
Albizzi         0.212454
Salviati        0.142857
Ridolfi         0.113553
Bischeri        0.104396
Strozzi         0.102564
Barbadori       0.093407
Tornabuoni      0.091575
Castellani      0.054945
Peruzzi         0.021978
Lamberteschi    0.000000
Ginori          0.000000
Pazzi           0.000000
Acciaiuoli      0.000000
Name: betweenness, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">bc</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_40_0.png" alt="png" /></p>

<h3 id="eigen-vector-centrality">Eigen(vector) Centrality</h3>

<p>Jury&rsquo;s still out on the specific <em>interpretation</em> of this measure (<a href="https://github.com/networkx/networkx/issues/4650">link to unanswered GitHub question, at the time of writing</a>), but the <em>general idea</em> is reasonably-simple to follow:</p>

<ul>
<li>Eigenvector Centrality starts off randomly-instantiated, then is <em>recursively generated</em> from the network</li>
<li>For a given node, connections to high-Eigenvector Centrality contribute more to the node&rsquo;s score than low-scoring nodes</li>
</ul>

<p>Or as the author of the books puts it</p>

<blockquote>
<p>&ldquo;Tell me who your friends are and I&rsquo;ll tell you who <em>you</em> are&rdquo;</p>
</blockquote>

<p>Which seems to apply some notion of assorativity, yeah?</p>

<p>More generally, this measure is particularly useful in contexts where communication within a network happens over long distances. Here, the position of a node <em>in the global structure</em> counts for more than how <em>locally connected</em> a node might be.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">ec</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">eigenvector_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">ec</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">ec</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;eigenvector&#39;</span><span class="p">)</span>

<span class="n">ec</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.430315
Strozzi         0.355973
Ridolfi         0.341554
Tornabuoni      0.325847
Guadagni        0.289117
Bischeri        0.282794
Peruzzi         0.275722
Castellani      0.259020
Albizzi         0.243961
Barbadori       0.211706
Salviati        0.145921
Acciaiuoli      0.132157
Lamberteschi    0.088793
Ginori          0.074925
Pazzi           0.044815
Name: eigenvector, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">ec</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_43_0.png" alt="png" /></p>

<h3 id="page-rank">Page Rank</h3>

<p>Like Eigenvector Centrality, PageRank is a <em>recursively defined</em> Centrality Measure that considers the scores of a node&rsquo;s neighbors in the score calculation for a given node. But whereas Eigenvector Centrality is a plug-and-chug calculation of the adjacency matrix, PageRank employs a more tangible algorithm.</p>

<p>All told, a node&rsquo;s PageRank score (loosely) represents &ldquo;the probability that a person randomly traversing edges will arrive at the node.&rdquo; We say &lsquo;probability&rsquo; because there&rsquo;s an element of chance at play here.</p>

<p>Let&rsquo;s back up.</p>

<p>PageRank is an algorithm that works <em>exclusively</em> on <strong>Directed</strong> graphs. When we pass in an <em>undirected</em> graph&ndash; like the one we&rsquo;ve been working with thus far&ndash; under the hood, we re-cast this as a Directed Graph with twice as many edges (one for each direction). Then, we re-weight each edge such that all of the weights add to 1 (we can bias the starting condition, but let&rsquo;s ignore that for now).</p>

<p>Then <code>networkx</code> pipes this DiGraph into a Stochastic Graph object, which essentially uses the edge weights to simulate random walks through the network.</p>

<p>Using this, <a href="https://networkx.org/documentation/stable/_modules/networkx/algorithms/link_analysis/pagerank_alg.html#pagerank">we simulate several rounds where we</a>:</p>

<ul>
<li>Simulate random movement through the network</li>
<li>Tabulate how much our data has sunk into <code>dangling_nodes</code>&ndash; or nodes that don&rsquo;t have an out edge&ndash; the more data pooling in the terminal nodes, the more <em>important</em> those terminal nodes</li>
<li>Similarly, when the terminal nodes increase in value, <em>the nodes responsible for pushing data to them become more valueable</em></li>
<li>Thus, we back-propogate a big chunk of value to the penultimate nodes, a moderate chunk to the second-to-last nodes, etc, etc</li>
</ul>

<p>This runs until the aggregate, intra-node, round-to-round movements converge to some small value and we&rsquo;re left with a network that&rsquo;s more or less stable.</p>

<p>The wrinkle&ndash; and indeed, the brilliance&ndash; to all of this, is that at each step, there&rsquo;s an <code>alpha</code> value (default=<code>.85</code>) that the simulated user/entity will move again after this round. Or stated in the reverse, there&rsquo;s a <code>p=.15</code> chance they just stop at whatever node they were at, on round <code>t</code>.</p>

<p>This allows for some interesting (and more-realistic) simulation of user behavior. At the two extremes:</p>

<ul>
<li><code>alpha=1</code>: All actors move until they sink into a node with no way out (think long-term Markov Chain behavior). Calculate PageRank accordingly.</li>
<li><code>alpha=0</code>: There&rsquo;s a <code>p=1.00</code> chance that the agents don&rsquo;t take a single step. Page Rank will just be <code>1 / N</code> for each node.</li>
</ul>

<p>Thus, picking the correct value for <code>alpha</code> means striking a balance that finds &ldquo;realistic randomness.&rdquo;</p>

<p>But until we know what we&rsquo;re doing, let&rsquo;s stick with the default, lol</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">pr</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">pagerank</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">pr</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">pr</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;pagerank&#39;</span><span class="p">)</span>

<span class="n">pr</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span></code></pre></div>
<pre><code>Medici          0.145818
Guadagni        0.098399
Strozzi         0.088098
Albizzi         0.079122
Tornabuoni      0.071279
Ridolfi         0.069574
Castellani      0.069330
Bischeri        0.068862
Peruzzi         0.067875
Salviati        0.061303
Barbadori       0.050301
Pazzi           0.036054
Ginori          0.032418
Lamberteschi    0.030909
Acciaiuoli      0.030657
Name: pagerank, dtype: float64
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">draw_network_plot</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">pr</span><span class="p">)</span></code></pre></div>
<p><img src="centrality_measures_46_0.png" alt="png" /></p>

<p>Making a note of it here, the book mentions &ldquo;HITS Hubs and Authorities&rdquo; as <em>similar, but opposite</em> approaches to PageRank. Will come back and update these notes if I find that it&rsquo;s convincingly-different from what we&rsquo;ve covered thus far.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">hits</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">hits</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">hits</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">hits</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;hits&#39;</span><span class="p">)</span></code></pre></div>
<h2 id="so-what-s-best">So What&rsquo;s &ldquo;Best?&rdquo;</h2>

<p><em>Whatever that means&hellip;.</em></p>

<p>For starters, let&rsquo;s merge all of the results into one big ol&rsquo; DataFrame</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">dc</span><span class="p">,</span> <span class="n">cc</span><span class="p">,</span> <span class="n">hc</span><span class="p">,</span> <span class="n">ec</span><span class="p">,</span> <span class="n">bc</span><span class="p">,</span> <span class="n">pr</span><span class="p">,</span> <span class="n">hits</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>degree</th>
      <th>closeness</th>
      <th>harmoinic</th>
      <th>eigenvector</th>
      <th>betweenness</th>
      <th>pagerank</th>
      <th>hits</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Acciaiuoli</th>
      <td>0.071429</td>
      <td>0.368421</td>
      <td>0.422619</td>
      <td>0.132157</td>
      <td>0.000000</td>
      <td>0.030657</td>
      <td>0.037730</td>
    </tr>
    <tr>
      <th>Medici</th>
      <td>0.428571</td>
      <td>0.560000</td>
      <td>0.678571</td>
      <td>0.430315</td>
      <td>0.521978</td>
      <td>0.145818</td>
      <td>0.122853</td>
    </tr>
    <tr>
      <th>Castellani</th>
      <td>0.214286</td>
      <td>0.388889</td>
      <td>0.494048</td>
      <td>0.259020</td>
      <td>0.054945</td>
      <td>0.069330</td>
      <td>0.073952</td>
    </tr>
    <tr>
      <th>Peruzzi</th>
      <td>0.214286</td>
      <td>0.368421</td>
      <td>0.484524</td>
      <td>0.275722</td>
      <td>0.021978</td>
      <td>0.067875</td>
      <td>0.078721</td>
    </tr>
    <tr>
      <th>Strozzi</th>
      <td>0.285714</td>
      <td>0.437500</td>
      <td>0.559524</td>
      <td>0.355973</td>
      <td>0.102564</td>
      <td>0.088098</td>
      <td>0.101633</td>
    </tr>
    <tr>
      <th>Barbadori</th>
      <td>0.142857</td>
      <td>0.437500</td>
      <td>0.505952</td>
      <td>0.211706</td>
      <td>0.093407</td>
      <td>0.050301</td>
      <td>0.060442</td>
    </tr>
    <tr>
      <th>Ridolfi</th>
      <td>0.214286</td>
      <td>0.500000</td>
      <td>0.571429</td>
      <td>0.341554</td>
      <td>0.113553</td>
      <td>0.069574</td>
      <td>0.097514</td>
    </tr>
    <tr>
      <th>Tornabuoni</th>
      <td>0.214286</td>
      <td>0.482759</td>
      <td>0.559524</td>
      <td>0.325847</td>
      <td>0.091575</td>
      <td>0.071279</td>
      <td>0.093028</td>
    </tr>
    <tr>
      <th>Albizzi</th>
      <td>0.214286</td>
      <td>0.482759</td>
      <td>0.559524</td>
      <td>0.243961</td>
      <td>0.212454</td>
      <td>0.079122</td>
      <td>0.069650</td>
    </tr>
    <tr>
      <th>Salviati</th>
      <td>0.142857</td>
      <td>0.388889</td>
      <td>0.470238</td>
      <td>0.145921</td>
      <td>0.142857</td>
      <td>0.061303</td>
      <td>0.041659</td>
    </tr>
    <tr>
      <th>Pazzi</th>
      <td>0.071429</td>
      <td>0.285714</td>
      <td>0.340476</td>
      <td>0.044815</td>
      <td>0.000000</td>
      <td>0.036054</td>
      <td>0.012794</td>
    </tr>
    <tr>
      <th>Bischeri</th>
      <td>0.214286</td>
      <td>0.400000</td>
      <td>0.514286</td>
      <td>0.282794</td>
      <td>0.104396</td>
      <td>0.068862</td>
      <td>0.080740</td>
    </tr>
    <tr>
      <th>Guadagni</th>
      <td>0.285714</td>
      <td>0.466667</td>
      <td>0.577381</td>
      <td>0.289117</td>
      <td>0.254579</td>
      <td>0.098399</td>
      <td>0.082543</td>
    </tr>
    <tr>
      <th>Ginori</th>
      <td>0.071429</td>
      <td>0.333333</td>
      <td>0.380952</td>
      <td>0.074925</td>
      <td>0.000000</td>
      <td>0.032418</td>
      <td>0.021390</td>
    </tr>
    <tr>
      <th>Lamberteschi</th>
      <td>0.071429</td>
      <td>0.325581</td>
      <td>0.383333</td>
      <td>0.088793</td>
      <td>0.000000</td>
      <td>0.030909</td>
      <td>0.025350</td>
    </tr>
  </tbody>
</table>
</div>

<p>Then we&rsquo;ll employ the favorite blunt instrument of any Data Scientist.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">df</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span></code></pre></div>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>degree</th>
      <th>closeness</th>
      <th>harmoinic</th>
      <th>eigenvector</th>
      <th>betweenness</th>
      <th>pagerank</th>
      <th>hits</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>degree</th>
      <td>1.000000</td>
      <td>0.824514</td>
      <td>0.929537</td>
      <td>0.925372</td>
      <td>0.844151</td>
      <td>0.985759</td>
      <td>0.925369</td>
    </tr>
    <tr>
      <th>closeness</th>
      <td>0.824514</td>
      <td>1.000000</td>
      <td>0.964901</td>
      <td>0.868137</td>
      <td>0.806630</td>
      <td>0.824776</td>
      <td>0.868119</td>
    </tr>
    <tr>
      <th>harmoinic</th>
      <td>0.929537</td>
      <td>0.964901</td>
      <td>1.000000</td>
      <td>0.947494</td>
      <td>0.821570</td>
      <td>0.913117</td>
      <td>0.947483</td>
    </tr>
    <tr>
      <th>eigenvector</th>
      <td>0.925372</td>
      <td>0.868137</td>
      <td>0.947494</td>
      <td>1.000000</td>
      <td>0.665501</td>
      <td>0.864561</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>betweenness</th>
      <td>0.844151</td>
      <td>0.806630</td>
      <td>0.821570</td>
      <td>0.665501</td>
      <td>1.000000</td>
      <td>0.913238</td>
      <td>0.665479</td>
    </tr>
    <tr>
      <th>pagerank</th>
      <td>0.985759</td>
      <td>0.824776</td>
      <td>0.913117</td>
      <td>0.864561</td>
      <td>0.913238</td>
      <td>1.000000</td>
      <td>0.864552</td>
    </tr>
    <tr>
      <th>hits</th>
      <td>0.925369</td>
      <td>0.868119</td>
      <td>0.947483</td>
      <td>1.000000</td>
      <td>0.665479</td>
      <td>0.864552</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>And I&rsquo;m told if you stare at this long enough, you might intuit that these measures fall, broadly, into two classes:</p>

<ul>
<li>Group A: [&lsquo;Eigenvector&rsquo;, &lsquo;Harmonic&rsquo;, &lsquo;PageRank&rsquo;]</li>
<li>Group B:

<ul>
<li>Subgroup I: [&lsquo;Degree&rsquo;, &lsquo;Betweenness&rsquo;]</li>
<li>Subgroup II: [&lsquo;Closeness&rsquo;, &lsquo;HITS&rsquo;]
<br /></li>
</ul></li>
</ul>

<p>He then goes on to say (emphasis mine&ndash; words entirely his, please don&rsquo;t DMCA me)</p>

<blockquote>
<p>I am <em>almost</em> saying that knowing one representative measure from each group&ndash; say, closeness, betweeness, and eigenvector centralities&ndash; <em>probably</em> will suffice for all practical purposes. <strong>But the final choice is yours.</strong></p>
</blockquote>

<p>Like HITS, I&rsquo;ll come back and update this section if this understanding winds up biting me in the ass.</p>

</div>
  <aside>
      <div class="bug_reporting">
          <h4>Find an error or bug?</h4>
          <p>Everything on this site is available on GitHub. Head to <a href='https://github.com/napsterinblue/notes/issues/new'>and submit a suggested change</a>. You can also message me directly on <a href='https://twitter.com/napsterinblue'>Twitter</a>.</p>
      </div>
      </aside>

    </div>
</article>




            </div>

        </div>
    </div>

    

    <footer class="footer text-center">
        <div class="container">
            <span class="text-muted">This project contains 185 pages and is available on <a href="https://github.com/napsterinblue/notes">GitHub</a>. Copyright &copy; NapsterInBlue, <time datetime="2018">2018</time>.</span>
        </div>
    </footer>

    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
        crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.3/umd/popper.min.js" integrity="sha384-vFJXuSJphROIrBnz7yo7oB41mKfc8JzQZiCq4NCceLEaO4IHwicKwpJf9c9IpFgh"
        crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0-beta.2/js/bootstrap.min.js" integrity="sha384-alpBpkh1PFOepccYVYDB4do5UnbKysX5WZXm3XxPqe5iKTfUKjNkCk9SaVuEZflJ"
        crossorigin="anonymous"></script>

</body>

</html>
